# MLSP Project Team 9

| File | Description|
|------|------------|
|`projet.ipynb`|DEMUCS+Basic Pitch part of our pipeline tested on the file `data/rock.wav`|
|`qwen2-finetuning.py`|Fine-Tuning script that fetches and trains Qwen2 Audio Instruct|
|`run.sh`|Script to start a slurm batch for `qwen2-finetuning.py` on Compute Canada|
|`qwen2-test.py`|Run inference on Qwen2 Audio Instruct|
|`remi.py`|Used to verify the output of the REMI tokenizer on a specific MIDI file|
|`remi.json`|Used to load back the REMI tokenizer that we've used during this project|
|`reverb_test.ipynb`|Test the Reverb module from the audio augmentations library on a sample speech file|
|`fine-tuning-results/`|JSON output of the training script along with graphs generated by `make_graphs.py`|
|`torchaudio_augmentations/`|Updated library for audio data augmentations, based on [Spijkervet/torchaudio_augmentations](https://github.com/Spijkervet/torchaudio-augmentations)|
|`dataset_generator/`|Scripts to generate our dataset, which includes guitar and violin, and audio, MPE and MIDI samples for each instrument. Requires the [Equator 2 software](https://roli.com/us/product/equator2?srsltid=AfmBOoqg-71q3_fQ_NjAdlGFAgZ0oiwyd275pps1u-xFZrZUQ4S_7-vI)|

The necessary python packages are in `requirements.txt`. Python3.10 is required (exactly this version) for Basic Pitch. It's also important to make sure that ONNX is installed and that tensorflow isn't so that Basic Pitch uses PyTorch for inference.

To reproduce our results, first you would run the notebook `projet.ipynb` to test DEMUCS and Basic Pitch.

Then you would generate the data using the code in `dataset_generator/`, place it in `training_data/` at the root of this repository's directory. To run qwen2-finetuning.py, you need a GPU with at least 24GB of free VRAM. 16GB of DRAM should be enough. The script takes about 7 hours on Compute Canada with 10 epochs, so feel free to reduce the amount of epochs to 3. Optimal results are seen at around 5-6 epochs. It's important to stdout to a file.

This will give you the JSON output in the script logs, which you can paste into a file, split into training and eval json files, encase in brackets, run `sed -i -e '$!s/$/,/' file.json` to add comas at the end of the lines, run `sed -i -e "s/'/\"/g" file.json` to replace the single quotes with JSON-compatible double quotes, modify `make-graphs.py` to read these files, and run it to find the graphs that we've included in the report.

`qwen2-finetuning.py` prints the paths of the files it doesn't train on, which are used for eval. You can then run `qwen2-test.py` on any of these files to verify the inference output on test data, or on any other sample to verify the output on training data.
